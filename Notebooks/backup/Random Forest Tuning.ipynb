{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4102f31",
   "metadata": {},
   "source": [
    "# Spotify Music Popularity Capstone - Modeling\n",
    "\n",
    "Greg Welliver   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba529c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries and packages.\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import matplotlib.ticker as plticker\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.api import abline_plot\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import linear_model, preprocessing, tree, svm, datasets, metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, roc_auc_score, auc, mean_squared_error, r2_score, f1_score, log_loss\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "from datetime import datetime, timedelta, date\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import itertools\n",
    "from io import StringIO  \n",
    "import pydotplus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7517020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233445</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120671</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68604</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160156</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52414</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Top100\n",
       "233445       1\n",
       "120671       1\n",
       "68604        1\n",
       "160156       0\n",
       "52414        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "X_train = pd.read_csv('/Users/gregwelliver/Desktop/springboard_files/Music-Popularity-Capstone-Repo/Data/X_train.csv', index_col =[0])\n",
    "X_test = pd.read_csv('/Users/gregwelliver/Desktop/springboard_files/Music-Popularity-Capstone-Repo/Data/X_test.csv', index_col =[0])\n",
    "y_train = pd.read_csv('/Users/gregwelliver/Desktop/springboard_files/Music-Popularity-Capstone-Repo/Data/y_train.csv', index_col =[0]) \n",
    "y_test = pd.read_csv('/Users/gregwelliver/Desktop/springboard_files/Music-Popularity-Capstone-Repo/Data/y_test.csv', index_col =[0])\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe681e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e909def",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84848e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 123,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# look at available hyperparameters\n",
    "rf = RandomForestClassifier(random_state = 123)\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdb5505",
   "metadata": {},
   "source": [
    "Scikit-Learn documentation tells us that the most important settings are the number of trees in the forest (n_estimators) and the number of features considered for splitting at each leaf node (max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a26a52",
   "metadata": {},
   "source": [
    "We will try adjusting the following set of hyperparameters:\n",
    "\n",
    "- n_estimators = number of trees in the foreset\n",
    "- max_features = max number of features considered for splitting a node\n",
    "- max_depth = max number of levels in each decision tree\n",
    "- min_samples_split = min number of data points placed in a node before the node is split\n",
    "- min_samples_leaf = min number of data points allowed in a leaf node\n",
    "- bootstrap = method for sampling data points (with or without replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2cb2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a420e074",
   "metadata": {},
   "source": [
    "#### Build Random Forest Model\n",
    "First, we will train the model with default Random Forest Classifier Hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45a1299d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86       378\n",
      "           1       0.84      0.90      0.87       368\n",
      "\n",
      "    accuracy                           0.87       746\n",
      "   macro avg       0.87      0.87      0.87       746\n",
      "weighted avg       0.87      0.87      0.87       746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=123)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "  \n",
    "# predict the mode\n",
    "y_pred = model.predict(X_test)\n",
    "  \n",
    "# performance evaluatio metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c958032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1485\n",
      "           1       1.00      1.00      1.00      1495\n",
      "\n",
      "    accuracy                           1.00      2980\n",
      "   macro avg       1.00      1.00      1.00      2980\n",
      "weighted avg       1.00      1.00      1.00      2980\n",
      "\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86       378\n",
      "           1       0.84      0.90      0.87       368\n",
      "\n",
      "    accuracy                           0.87       746\n",
      "   macro avg       0.87      0.87      0.87       746\n",
      "weighted avg       0.87      0.87      0.87       746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, model.predict(X_train)))\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4c35028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [25, 50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'max_leaf_nodes': [3, 6, 9],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde0dd4f",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning- GridSearchCV\n",
    "First, let’s use GridSearchCV to obtain the best parameters for the model. For that, we will pass RandomFoestClassifier() instance to the model and then fit the GridSearchCV using the training data to find the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "997318cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=6, max_features=None, max_leaf_nodes=9,\n",
      "                       n_estimators=150, random_state=123)\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=123),\n",
    "                           param_grid=param_grid)\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f011855f",
   "metadata": {},
   "source": [
    "#### Update the Model\n",
    "Now we will update the parameters of the model by those which are obtained by using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a71d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid = RandomForestClassifier(max_depth=6,\n",
    "                                    max_leaf_nodes=9,\n",
    "                                    n_estimators=150, random_state=123)\n",
    "model_grid.fit(X_train, y_train.values.ravel())\n",
    "y_pred_grid = model_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4612ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.84      1485\n",
      "           1       0.80      0.94      0.86      1495\n",
      "\n",
      "    accuracy                           0.85      2980\n",
      "   macro avg       0.86      0.85      0.85      2980\n",
      "weighted avg       0.86      0.85      0.85      2980\n",
      "\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.74      0.82       378\n",
      "           1       0.77      0.93      0.85       368\n",
      "\n",
      "    accuracy                           0.83       746\n",
      "   macro avg       0.85      0.83      0.83       746\n",
      "weighted avg       0.85      0.83      0.83       746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, model_grid.predict(X_train)))\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, model_grid.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14a74c3",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning- RandomizedSearchCV\n",
    "Now let’s use RandomizedSearchCV to obtain the best parameters for the model. For that, we will pass RandomFoestClassifier() instance to the model and then fit the RandomizedSearchCV using the training data to find the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f62313a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=9, max_features=None, max_leaf_nodes=9,\n",
      "                       n_estimators=50, random_state=123)\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(RandomForestClassifier(random_state=123),\n",
    "                                   param_grid)\n",
    "random_search.fit(X_train, y_train.values.ravel())\n",
    "print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92acf334",
   "metadata": {},
   "source": [
    "#### Update the model\n",
    "Now we will update the parameters of the model by those which are obtained by using RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62fa65b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_random = RandomForestClassifier(max_depth=9,\n",
    "                                      max_leaf_nodes=9,\n",
    "                                      n_estimators=50, random_state=123)\n",
    "model_random.fit(X_train, y_train.values.ravel())\n",
    "y_pred_rand = model_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b80e3261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.73      0.81      1485\n",
      "           1       0.77      0.93      0.85      1495\n",
      "\n",
      "    accuracy                           0.83      2980\n",
      "   macro avg       0.84      0.83      0.83      2980\n",
      "weighted avg       0.84      0.83      0.83      2980\n",
      "\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80       378\n",
      "           1       0.76      0.92      0.83       368\n",
      "\n",
      "    accuracy                           0.82       746\n",
      "   macro avg       0.83      0.82      0.82       746\n",
      "weighted avg       0.83      0.82      0.82       746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, model_random.predict(X_train)))\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, model_random.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff1c79",
   "metadata": {},
   "source": [
    "#### Random Search Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5768bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "RandomForestClassifier(max_depth=6, max_features=None, max_leaf_nodes=9,\n",
      "                       random_state=123)\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(RandomForestClassifier(random_state=123),\n",
    "                                   param_grid, n_iter = 100, cv = 3, verbose=2, random_state=123, n_jobs = -1)\n",
    "random_search.fit(X_train, y_train.values.ravel())\n",
    "print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d15dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_random = RandomForestClassifier(max_depth=6,\n",
    "                                      max_leaf_nodes=9,\n",
    "                                      random_state=123)\n",
    "model_random.fit(X_train, y_train.values.ravel())\n",
    "y_pred_rand = model_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8544913b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.75      0.83      1485\n",
      "           1       0.79      0.94      0.86      1495\n",
      "\n",
      "    accuracy                           0.84      2980\n",
      "   macro avg       0.86      0.84      0.84      2980\n",
      "weighted avg       0.86      0.84      0.84      2980\n",
      "\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.73      0.81       378\n",
      "           1       0.77      0.93      0.84       368\n",
      "\n",
      "    accuracy                           0.83       746\n",
      "   macro avg       0.84      0.83      0.83       746\n",
      "weighted avg       0.84      0.83      0.83       746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, model_random.predict(X_train)))\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, model_random.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a145fa7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274151d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02805a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fbc36b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06361282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e1e16da",
   "metadata": {},
   "source": [
    "### User Random Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e2b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first need to create a parameter grid to sample from during fitting\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 5, stop = 200, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(3, 50, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5271f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the random search and fit it\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=123, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train.values.ravel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9f5dbd",
   "metadata": {},
   "source": [
    "The most important arguments in RandomizedSearchCV are n_iter, which controls the number of different combinations to try, and cv which is the number of folds to use for cross validation (we use 100 and 3 respectively). More iterations will cover a wider search space and more cv folds reduces the chances of overfitting, but raising each will increase the run time. Machine learning is a field of trade-offs, and performance vs time is one of the most fundamental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70663e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can view the best parameters from fitting the random search:\n",
    "rf_random.best_params_\n",
    "\n",
    "# From these results, we should be able to narrow the range of values for each hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9564825b",
   "metadata": {},
   "source": [
    "### Evaluate Random Search\n",
    "To determine if random search yielded a better model, we compare the base model with the best random search model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f8e602",
   "metadata": {},
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    errors = abs(predictions - y_test)\n",
    "    mape = 100 * np.mean(errors / y_test)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 123)\n",
    "base_model.fit(X_train, y_train.values.ravel())\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, test_features, test_labels)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c2bd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd14c848",
   "metadata": {},
   "source": [
    "### Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29cd19",
   "metadata": {},
   "source": [
    "Random search allowed us to narrow down the range for each hyperparameter. Now that we know where to concentrate our search, we can explicitly specify every combination of settings to try. We do this with GridSearchCV, a method that, instead of sampling randomly from a distribution, evaluates all combinations we define. To use Grid Search, we make another grid based on the best values provided by random search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c76aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [40, 50, 60, 70],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samplems_leaf': [2, 3],\n",
    "    'min_samples_split': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 200, 5000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde4bc9",
   "metadata": {},
   "source": [
    "We can fit the model, display the best hyperparameters, and evaluate performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587e2758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_\n",
    "\n",
    "# {'bootstrap': True,\n",
    "#  'max_depth': 80,\n",
    "#  'max_features': 3,\n",
    "#  'min_samples_leaf': 5,\n",
    "#  'min_samples_split': 12,\n",
    "#  'n_estimators': 100}\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X_test, y_test)\n",
    "\n",
    "# Model Performance\n",
    "# Average Error: 3.6561 degrees.\n",
    "# Accuracy = 93.83%.\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))\n",
    "\n",
    "# Improvement of 0.50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f03d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58680415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf7ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb0f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=3, random_state = 123, n_jobs=-1)\n",
    "model_res = rf_clf.fit(X_train, y_train.values.ravel())\n",
    "print('Accuracy on training set:',rf_clf.score(X_train,y_train))\n",
    "print('Accuracy on test set:',rf_clf.score(X_test,y_test))\n",
    "y_pred = model_res.predict(X_test)\n",
    "y_pred_prob = model_res.predict_proba(X_test)\n",
    "lr_probs = y_pred_prob[:,1]\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Random Forest: Accuracy=%.3f' % (ac))\n",
    "\n",
    "print('Random Forest: f1-score=%.3f' % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880627ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at classification report\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, rf_clf.predict(X_train)))\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, rf_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14062f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4243f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=300, random_state = 123, n_jobs=-1)\n",
    "model_res = rf_clf.fit(X_train, y_train.values.ravel())\n",
    "print('Accuracy on training set:',rf_clf.score(X_train,y_train))\n",
    "print('Accuracy on test set:',rf_clf.score(X_test,y_test))\n",
    "y_pred = model_res.predict(X_test)\n",
    "y_pred_prob = model_res.predict_proba(X_test)\n",
    "lr_probs = y_pred_prob[:,1]\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Random Forest: Accuracy=%.3f' % (ac))\n",
    "\n",
    "print('Random Forest: f1-score=%.3f' % (f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb6d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at classification report\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, rf_clf.predict(X_train)))\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, rf_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at confusion matrix\n",
    "class_names=['0','1'] # name  of classes\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(False)\n",
    "    #plt.rcParams.update({'font.size': 7})\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "#plt.savefig('figures/RF_cm_multi_class.png')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "#plt.savefig('figures/RF_cm_proportion_multi_class.png', bbox_inches=\"tight\")\n",
    "#plt.rcParams.update({'font.size': 7})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3066569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importances\n",
    "feature_importance = rf_clf.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())[:30]\n",
    "sorted_idx = np.argsort(feature_importance)[:30]\n",
    "\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "print(pos.size)\n",
    "sorted_idx.size\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a2ae03",
   "metadata": {},
   "source": [
    "#### QUESTIONS: \n",
    "- should i try someting here to optimize the number of estimators?\n",
    "- should accuracy of training data be 1.0?\n",
    "- in most of my calculations, accuracy and F1 score were either the same, or very close. is this expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc108239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd5e9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dd8266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924ba100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa54ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e4f030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b985625",
   "metadata": {},
   "source": [
    "#### write to CSV\n",
    "from pathlib import Path  \n",
    "filepath = Path('/Users/gregwelliver/Desktop/springboard_files/Music-Popularity-Capstone-Repo/Data/df_data_scaled.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb639828",
   "metadata": {},
   "source": [
    "#### write to parquet\n",
    "from pathlib import Path  \n",
    "filepath = Path('/Users/gregwelliver/Desktop/springboard_files/Music-Popularity-Capstone-Repo/Data/df_data_scaled_pq2.parquet')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df.to_parquet(filepath, \n",
    "              engine = \"pyarrow\", \n",
    "              compression = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50af534",
   "metadata": {},
   "source": [
    "df = pd.read_parquet('/Users/gregwelliver/Desktop/springboard_files/Music-Popularity-Capstone-Repo/Data/df_data_scaled_pq.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf1c377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
